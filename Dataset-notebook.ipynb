{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Descriptors cannot not be created directly.\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\n 1. Downgrade the protobuf package to 3.20.x or lower.\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m AutoTokenizer\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m Dataset \u001b[39mas\u001b[39;00m TransformersDataset, load_dataset\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/__init__.py:30\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m TYPE_CHECKING\n\u001b[1;32m     29\u001b[0m \u001b[39m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m dependency_versions_check\n\u001b[1;32m     31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     32\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[1;32m     33\u001b[0m     _LazyModule,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     44\u001b[0m     logging,\n\u001b[1;32m     45\u001b[0m )\n\u001b[1;32m     48\u001b[0m logger \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mget_logger(\u001b[39m__name__\u001b[39m)  \u001b[39m# pylint: disable=invalid-name\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/dependency_versions_check.py:36\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[39mif\u001b[39;00m pkg \u001b[39min\u001b[39;00m deps:\n\u001b[1;32m     34\u001b[0m     \u001b[39mif\u001b[39;00m pkg \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtokenizers\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     35\u001b[0m         \u001b[39m# must be loaded here, or else tqdm check may fail\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m         \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m is_tokenizers_available\n\u001b[1;32m     38\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m is_tokenizers_available():\n\u001b[1;32m     39\u001b[0m             \u001b[39mcontinue\u001b[39;00m  \u001b[39m# not required, check version only if installed\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/utils/__init__.py:34\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mconstants\u001b[39;00m \u001b[39mimport\u001b[39;00m IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD, IMAGENET_STANDARD_MEAN, IMAGENET_STANDARD_STD\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdoc\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     27\u001b[0m     add_code_sample_docstrings,\n\u001b[1;32m     28\u001b[0m     add_end_docstrings,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m     replace_return_docstrings,\n\u001b[1;32m     33\u001b[0m )\n\u001b[0;32m---> 34\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mgeneric\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     35\u001b[0m     ContextManagers,\n\u001b[1;32m     36\u001b[0m     ExplicitEnum,\n\u001b[1;32m     37\u001b[0m     ModelOutput,\n\u001b[1;32m     38\u001b[0m     PaddingStrategy,\n\u001b[1;32m     39\u001b[0m     TensorType,\n\u001b[1;32m     40\u001b[0m     cached_property,\n\u001b[1;32m     41\u001b[0m     can_return_loss,\n\u001b[1;32m     42\u001b[0m     expand_dims,\n\u001b[1;32m     43\u001b[0m     find_labels,\n\u001b[1;32m     44\u001b[0m     flatten_dict,\n\u001b[1;32m     45\u001b[0m     is_jax_tensor,\n\u001b[1;32m     46\u001b[0m     is_numpy_array,\n\u001b[1;32m     47\u001b[0m     is_tensor,\n\u001b[1;32m     48\u001b[0m     is_tf_tensor,\n\u001b[1;32m     49\u001b[0m     is_torch_device,\n\u001b[1;32m     50\u001b[0m     is_torch_dtype,\n\u001b[1;32m     51\u001b[0m     is_torch_tensor,\n\u001b[1;32m     52\u001b[0m     reshape,\n\u001b[1;32m     53\u001b[0m     squeeze,\n\u001b[1;32m     54\u001b[0m     tensor_size,\n\u001b[1;32m     55\u001b[0m     to_numpy,\n\u001b[1;32m     56\u001b[0m     to_py_obj,\n\u001b[1;32m     57\u001b[0m     transpose,\n\u001b[1;32m     58\u001b[0m     working_or_temp_dir,\n\u001b[1;32m     59\u001b[0m )\n\u001b[1;32m     60\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mhub\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     61\u001b[0m     CLOUDFRONT_DISTRIB_PREFIX,\n\u001b[1;32m     62\u001b[0m     DISABLE_TELEMETRY,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     88\u001b[0m     send_example_telemetry,\n\u001b[1;32m     89\u001b[0m )\n\u001b[1;32m     90\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mimport_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     91\u001b[0m     ENV_VARS_TRUE_AND_AUTO_VALUES,\n\u001b[1;32m     92\u001b[0m     ENV_VARS_TRUE_VALUES,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    169\u001b[0m     torch_version,\n\u001b[1;32m    170\u001b[0m )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/transformers/utils/generic.py:33\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mimport_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m is_flax_available, is_tf_available, is_torch_available, is_torch_fx_proxy\n\u001b[1;32m     32\u001b[0m \u001b[39mif\u001b[39;00m is_tf_available():\n\u001b[0;32m---> 33\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[39mif\u001b[39;00m is_flax_available():\n\u001b[1;32m     36\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mjax\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mjnp\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/__init__.py:37\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_typing\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtools\u001b[39;00m \u001b[39mimport\u001b[39;00m module_util \u001b[39mas\u001b[39;00m _module_util\n\u001b[1;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlazy_loader\u001b[39;00m \u001b[39mimport\u001b[39;00m LazyLoader \u001b[39mas\u001b[39;00m _LazyLoader\n\u001b[1;32m     40\u001b[0m \u001b[39m# Make sure code inside the TensorFlow codebase can use tf2.enabled() at import.\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/__init__.py:37\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39m# We aim to keep this file minimal and ideally remove completely.\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39m# If you are adding a new file with @tf_export decorators,\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39m# import it in modules_with_exports.py instead.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[39m# go/tf-wildcard-import\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[39m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m pywrap_tensorflow \u001b[39mas\u001b[39;00m _pywrap_tensorflow\n\u001b[0;32m---> 37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39meager\u001b[39;00m \u001b[39mimport\u001b[39;00m context\n\u001b[1;32m     39\u001b[0m \u001b[39m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[39m# Bring in subpackages.\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m \u001b[39mimport\u001b[39;00m data\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/python/eager/context.py:28\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mabsl\u001b[39;00m \u001b[39mimport\u001b[39;00m logging\n\u001b[1;32m     26\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m function_pb2\n\u001b[1;32m     29\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprotobuf\u001b[39;00m \u001b[39mimport\u001b[39;00m config_pb2\n\u001b[1;32m     30\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprotobuf\u001b[39;00m \u001b[39mimport\u001b[39;00m coordination_config_pb2\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/core/framework/function_pb2.py:16\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39m# @@protoc_insertion_point(imports)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m _sym_db \u001b[39m=\u001b[39m _symbol_database\u001b[39m.\u001b[39mDefault()\n\u001b[0;32m---> 16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m attr_value_pb2 \u001b[39mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_attr__value__pb2\n\u001b[1;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m node_def_pb2 \u001b[39mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_node__def__pb2\n\u001b[1;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m op_def_pb2 \u001b[39mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_op__def__pb2\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/core/framework/attr_value_pb2.py:16\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39m# @@protoc_insertion_point(imports)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m _sym_db \u001b[39m=\u001b[39m _symbol_database\u001b[39m.\u001b[39mDefault()\n\u001b[0;32m---> 16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m tensor_pb2 \u001b[39mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_tensor__pb2\n\u001b[1;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m tensor_shape_pb2 \u001b[39mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2\n\u001b[1;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m types_pb2 \u001b[39mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_types__pb2\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/core/framework/tensor_pb2.py:16\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39m# @@protoc_insertion_point(imports)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m _sym_db \u001b[39m=\u001b[39m _symbol_database\u001b[39m.\u001b[39mDefault()\n\u001b[0;32m---> 16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m resource_handle_pb2 \u001b[39mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_resource__handle__pb2\n\u001b[1;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m tensor_shape_pb2 \u001b[39mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2\n\u001b[1;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m types_pb2 \u001b[39mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_types__pb2\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/core/framework/resource_handle_pb2.py:16\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39m# @@protoc_insertion_point(imports)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m _sym_db \u001b[39m=\u001b[39m _symbol_database\u001b[39m.\u001b[39mDefault()\n\u001b[0;32m---> 16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m tensor_shape_pb2 \u001b[39mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2\n\u001b[1;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mframework\u001b[39;00m \u001b[39mimport\u001b[39;00m types_pb2 \u001b[39mas\u001b[39;00m tensorflow_dot_core_dot_framework_dot_types__pb2\n\u001b[1;32m     20\u001b[0m DESCRIPTOR \u001b[39m=\u001b[39m _descriptor\u001b[39m.\u001b[39mFileDescriptor(\n\u001b[1;32m     21\u001b[0m   name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtensorflow/core/framework/resource_handle.proto\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     22\u001b[0m   package\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtensorflow\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m   ,\n\u001b[1;32m     27\u001b[0m   dependencies\u001b[39m=\u001b[39m[tensorflow_dot_core_dot_framework_dot_tensor__shape__pb2\u001b[39m.\u001b[39mDESCRIPTOR,tensorflow_dot_core_dot_framework_dot_types__pb2\u001b[39m.\u001b[39mDESCRIPTOR,])\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tensorflow/core/framework/tensor_shape_pb2.py:36\u001b[0m\n\u001b[1;32m     13\u001b[0m _sym_db \u001b[39m=\u001b[39m _symbol_database\u001b[39m.\u001b[39mDefault()\n\u001b[1;32m     18\u001b[0m DESCRIPTOR \u001b[39m=\u001b[39m _descriptor\u001b[39m.\u001b[39mFileDescriptor(\n\u001b[1;32m     19\u001b[0m   name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtensorflow/core/framework/tensor_shape.proto\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     20\u001b[0m   package\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtensorflow\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m   serialized_pb\u001b[39m=\u001b[39m_b(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m,tensorflow/core/framework/tensor_shape.proto\u001b[39m\u001b[39m\\x12\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39mtensorflow\u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39mz\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\x10\u001b[39;00m\u001b[39mTensorShapeProto\u001b[39m\u001b[39m\\x12\u001b[39;00m\u001b[39m-\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\x03\u001b[39;00m\u001b[39m\\x64\u001b[39;00m\u001b[39mim\u001b[39m\u001b[39m\\x18\u001b[39;00m\u001b[39m\\x02\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\x03\u001b[39;00m\u001b[39m(\u001b[39m\u001b[39m\\x0b\u001b[39;00m\u001b[39m\\x32\u001b[39;00m\u001b[39m .tensorflow.TensorShapeProto.Dim\u001b[39m\u001b[39m\\x12\u001b[39;00m\u001b[39m\\x14\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\x0c\u001b[39;00m\u001b[39munknown_rank\u001b[39m\u001b[39m\\x18\u001b[39;00m\u001b[39m\\x03\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\x01\u001b[39;00m\u001b[39m(\u001b[39m\u001b[39m\\x08\u001b[39;00m\u001b[39m\\x1a\u001b[39;00m\u001b[39m!\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\x03\u001b[39;00m\u001b[39m\\x44\u001b[39;00m\u001b[39mim\u001b[39m\u001b[39m\\x12\u001b[39;00m\u001b[39m\\x0c\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\x04\u001b[39;00m\u001b[39msize\u001b[39m\u001b[39m\\x18\u001b[39;00m\u001b[39m\\x01\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\x01\u001b[39;00m\u001b[39m(\u001b[39m\u001b[39m\\x03\u001b[39;00m\u001b[39m\\x12\u001b[39;00m\u001b[39m\\x0c\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\x04\u001b[39;00m\u001b[39mname\u001b[39m\u001b[39m\\x18\u001b[39;00m\u001b[39m\\x02\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\x01\u001b[39;00m\u001b[39m(\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39mB\u001b[39m\u001b[39m\\x87\u001b[39;00m\u001b[39m\\x01\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\x18\u001b[39;00m\u001b[39morg.tensorflow.frameworkB\u001b[39m\u001b[39m\\x11\u001b[39;00m\u001b[39mTensorShapeProtosP\u001b[39m\u001b[39m\\x01\u001b[39;00m\u001b[39mZSgithub.com/tensorflow/tensorflow/tensorflow/go/core/framework/tensor_shape_go_proto\u001b[39m\u001b[39m\\xf8\u001b[39;00m\u001b[39m\\x01\u001b[39;00m\u001b[39m\\x01\u001b[39;00m\u001b[39m\\x62\u001b[39;00m\u001b[39m\\x06\u001b[39;00m\u001b[39mproto3\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     24\u001b[0m )\n\u001b[1;32m     29\u001b[0m _TENSORSHAPEPROTO_DIM \u001b[39m=\u001b[39m _descriptor\u001b[39m.\u001b[39mDescriptor(\n\u001b[1;32m     30\u001b[0m   name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mDim\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     31\u001b[0m   full_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtensorflow.TensorShapeProto.Dim\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     32\u001b[0m   filename\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     33\u001b[0m   file\u001b[39m=\u001b[39mDESCRIPTOR,\n\u001b[1;32m     34\u001b[0m   containing_type\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     35\u001b[0m   fields\u001b[39m=\u001b[39m[\n\u001b[0;32m---> 36\u001b[0m     _descriptor\u001b[39m.\u001b[39;49mFieldDescriptor(\n\u001b[1;32m     37\u001b[0m       name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39msize\u001b[39;49m\u001b[39m'\u001b[39;49m, full_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtensorflow.TensorShapeProto.Dim.size\u001b[39;49m\u001b[39m'\u001b[39;49m, index\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m     38\u001b[0m       number\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, \u001b[39mtype\u001b[39;49m\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, cpp_type\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m, label\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[1;32m     39\u001b[0m       has_default_value\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, default_value\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[1;32m     40\u001b[0m       message_type\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, enum_type\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, containing_type\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     41\u001b[0m       is_extension\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, extension_scope\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[1;32m     42\u001b[0m       serialized_options\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m, file\u001b[39m=\u001b[39;49mDESCRIPTOR),\n\u001b[1;32m     43\u001b[0m     _descriptor\u001b[39m.\u001b[39mFieldDescriptor(\n\u001b[1;32m     44\u001b[0m       name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mname\u001b[39m\u001b[39m'\u001b[39m, full_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtensorflow.TensorShapeProto.Dim.name\u001b[39m\u001b[39m'\u001b[39m, index\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m     45\u001b[0m       number\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m, \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39m9\u001b[39m, cpp_type\u001b[39m=\u001b[39m\u001b[39m9\u001b[39m, label\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m     46\u001b[0m       has_default_value\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, default_value\u001b[39m=\u001b[39m_b(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mdecode(\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m),\n\u001b[1;32m     47\u001b[0m       message_type\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, enum_type\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, containing_type\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     48\u001b[0m       is_extension\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, extension_scope\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     49\u001b[0m       serialized_options\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, file\u001b[39m=\u001b[39mDESCRIPTOR),\n\u001b[1;32m     50\u001b[0m   ],\n\u001b[1;32m     51\u001b[0m   extensions\u001b[39m=\u001b[39m[\n\u001b[1;32m     52\u001b[0m   ],\n\u001b[1;32m     53\u001b[0m   nested_types\u001b[39m=\u001b[39m[],\n\u001b[1;32m     54\u001b[0m   enum_types\u001b[39m=\u001b[39m[\n\u001b[1;32m     55\u001b[0m   ],\n\u001b[1;32m     56\u001b[0m   serialized_options\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     57\u001b[0m   is_extendable\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     58\u001b[0m   syntax\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mproto3\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     59\u001b[0m   extension_ranges\u001b[39m=\u001b[39m[],\n\u001b[1;32m     60\u001b[0m   oneofs\u001b[39m=\u001b[39m[\n\u001b[1;32m     61\u001b[0m   ],\n\u001b[1;32m     62\u001b[0m   serialized_start\u001b[39m=\u001b[39m\u001b[39m149\u001b[39m,\n\u001b[1;32m     63\u001b[0m   serialized_end\u001b[39m=\u001b[39m\u001b[39m182\u001b[39m,\n\u001b[1;32m     64\u001b[0m )\n\u001b[1;32m     66\u001b[0m _TENSORSHAPEPROTO \u001b[39m=\u001b[39m _descriptor\u001b[39m.\u001b[39mDescriptor(\n\u001b[1;32m     67\u001b[0m   name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTensorShapeProto\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     68\u001b[0m   full_name\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtensorflow.TensorShapeProto\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m   serialized_end\u001b[39m=\u001b[39m\u001b[39m182\u001b[39m,\n\u001b[1;32m    101\u001b[0m )\n\u001b[1;32m    103\u001b[0m _TENSORSHAPEPROTO_DIM\u001b[39m.\u001b[39mcontaining_type \u001b[39m=\u001b[39m _TENSORSHAPEPROTO\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/google/protobuf/descriptor.py:561\u001b[0m, in \u001b[0;36mFieldDescriptor.__new__\u001b[0;34m(cls, name, full_name, index, number, type, cpp_type, label, default_value, message_type, enum_type, containing_type, is_extension, extension_scope, options, serialized_options, has_default_value, containing_oneof, json_name, file, create_key)\u001b[0m\n\u001b[1;32m    555\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__new__\u001b[39m(\u001b[39mcls\u001b[39m, name, full_name, index, number, \u001b[39mtype\u001b[39m, cpp_type, label,\n\u001b[1;32m    556\u001b[0m             default_value, message_type, enum_type, containing_type,\n\u001b[1;32m    557\u001b[0m             is_extension, extension_scope, options\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    558\u001b[0m             serialized_options\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    559\u001b[0m             has_default_value\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, containing_oneof\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, json_name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    560\u001b[0m             file\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, create_key\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):  \u001b[39m# pylint: disable=redefined-builtin\u001b[39;00m\n\u001b[0;32m--> 561\u001b[0m   _message\u001b[39m.\u001b[39;49mMessage\u001b[39m.\u001b[39;49m_CheckCalledFromGeneratedFile()\n\u001b[1;32m    562\u001b[0m   \u001b[39mif\u001b[39;00m is_extension:\n\u001b[1;32m    563\u001b[0m     \u001b[39mreturn\u001b[39;00m _message\u001b[39m.\u001b[39mdefault_pool\u001b[39m.\u001b[39mFindExtensionByName(full_name)\n",
      "\u001b[0;31mTypeError\u001b[0m: Descriptors cannot not be created directly.\nIf this call came from a _pb2.py file, your generated code is out of date and must be regenerated with protoc >= 3.19.0.\nIf you cannot immediately regenerate your protos, some other possible workarounds are:\n 1. Downgrade the protobuf package to 3.20.x or lower.\n 2. Set PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION=python (but this will use pure-Python parsing and will be much slower).\n\nMore information: https://developers.google.com/protocol-buffers/docs/news/2022-05-06#python-updates"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from datasets import Dataset as TransformersDataset, load_dataset\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader,TensorDataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import StandardScaler, scale, MinMaxScaler\n",
    "# from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import math\n",
    "from einops import rearrange\n",
    "\n",
    "import os\n",
    "from os import path, walk\n",
    "import itertools\n",
    "import json\n",
    "import random\n",
    "import datetime\n",
    "import gc\n",
    "import time\n",
    "import re\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 333\n",
    "def seedBasic(seed=SEED):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    \n",
    "def seedTorch(seed=SEED):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "      \n",
    "# basic + torch \n",
    "def seedEverything(seed=SEED):\n",
    "    seedBasic(seed)\n",
    "    seedTorch(seed)\n",
    "\n",
    "SEED = 333\n",
    "def seedBasic(seed=SEED):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    \n",
    "def seedTorch(seed=SEED):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "      \n",
    "# basic + torch \n",
    "def seedEverything(seed=SEED):\n",
    "    seedBasic(seed)\n",
    "    seedTorch(seed)\n",
    "\n",
    "seedEverything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('t5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UL2Dataset():\n",
    "    def __init__(self,\n",
    "                 text_list,\n",
    "                 mu=3,\n",
    "                 d=0.2,\n",
    "                 probabilities={\"s\": 0.2, \"b\": 0.2, \"c\": 0.5},\n",
    "                 tokenizer=None):\n",
    "        \"\"\"\n",
    "        tokens_list: List of list of tokens\n",
    "        mu: mean span length\n",
    "        d: density of the corruption used in the bidirectional method\n",
    "        probabilities: probabilities for the corruption method\n",
    "            s: corrupt just the first tokens\n",
    "            b: corrupt uniformly (bidirectional)\n",
    "            c: corrupt the last tokens (causal)\n",
    "        \"\"\"\n",
    "        self.text_list = text_list\n",
    "        self.mu = mu\n",
    "        self.d = d\n",
    "        self.probabilities = probabilities\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.extra_ids = tokenizer.additional_special_tokens_ids #list(tokenizer.get_added_vocab().values())\n",
    "        \n",
    "    \n",
    "    def _s_noise(self, tokens):\n",
    "        l = len(tokens)\n",
    "        extra_id = self.extra_ids[0]\n",
    "        span_length = random.randint(self.mu, l//2) if l//2 > self.mu else random.randint(1, self.mu)\n",
    "        \n",
    "        target_tokens = [self.extra_ids[1]] + tokens[:span_length] + [extra_id]\n",
    "        tokens = [extra_id] + tokens[span_length:]\n",
    "        \n",
    "        return tokens, target_tokens\n",
    "    \n",
    "    def _c_noise(self, tokens):\n",
    "        l = len(tokens)\n",
    "        extra_id = self.extra_ids[0]\n",
    "        span_length = random.randint(self.mu, l//2) if l//2 > self.mu else random.randint(1, self.mu)\n",
    "        \n",
    "        target_tokens = [extra_id] + tokens[-span_length:] + [self.extra_ids[1]]\n",
    "        tokens = tokens[:-span_length] + [extra_id]\n",
    "        \n",
    "        return tokens, target_tokens\n",
    "    \n",
    "    def _b_noise(self, tokens):\n",
    "        l = len(tokens)\n",
    "        n = max(int(l * self.d), 1)\n",
    "        span_len_list = []\n",
    "        space_len_list = []\n",
    "        max_span = max(n//4, self.mu)\n",
    "        \n",
    "        while sum(span_len_list) < n:\n",
    "            span_len_list.append(random.randint(1, min(max_span, n - sum(span_len_list))))\n",
    "        \n",
    "        for j in range(len(span_len_list)):\n",
    "            space_len_list.append(random.randint(0,(l - n)-sum(space_len_list)-len(span_len_list)+j+1))\n",
    "        \n",
    "        reste = (l - n)-sum(space_len_list)\n",
    "        if reste > 0:\n",
    "            space_len_list.append(reste)\n",
    "        \n",
    "        target_tokens = []\n",
    "        x_tokens = []\n",
    "        if len(space_len_list) > 1:\n",
    "            kk = 1\n",
    "            while kk < len(space_len_list):\n",
    "                if space_len_list[kk] == 0:\n",
    "                    space_len_list.pop(kk)\n",
    "                    span_len_list[kk-1] += span_len_list.pop(kk)\n",
    "                    kk -= 1\n",
    "                kk += 1\n",
    "        \n",
    "        for k in range(len(space_len_list)):\n",
    "            a = sum(space_len_list[:k])\n",
    "            a += sum(span_len_list[:k])\n",
    "            b = a + space_len_list[k]\n",
    "            x_tokens.append(tokens[a:b])\n",
    "            if k < len(span_len_list):\n",
    "                x_tokens[len(x_tokens)-1] = x_tokens[len(x_tokens)-1] + [self.extra_ids[k]]\n",
    "                target_tokens.append([self.extra_ids[k]] + tokens[b: b + span_len_list[k]])\n",
    "            else:\n",
    "                h = len(target_tokens) - 1\n",
    "                target_tokens[h] = target_tokens[h] + [self.extra_ids[k]]\n",
    "          \n",
    "        \n",
    "        return [item for sublist in x_tokens for item in sublist], [item for sublist in target_tokens for item in sublist]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        text = self.text_list[index]\n",
    "        tokenizer_result = tokenizer(text, padding=False, truncation=True, add_special_tokens=False)\n",
    "        tokens = tokenizer_result['input_ids']\n",
    "        \n",
    "        func_args = [\n",
    "            self._s_noise,\n",
    "            self._b_noise,\n",
    "            self._c_noise\n",
    "        ]\n",
    "\n",
    "        # Choose random function\n",
    "        func, = random.choices(func_args,\n",
    "                                       weights=[\n",
    "                                           self.probabilities[\"s\"],\n",
    "                                           self.probabilities[\"b\"],\n",
    "                                           self.probabilities[\"c\"]\n",
    "                                       ])\n",
    "\n",
    "        # Call it\n",
    "        x, y = func(tokens)\n",
    "        \n",
    "        x_o = tokenizer.decode(x)\n",
    "        y_o = tokenizer.decode(y)\n",
    "        \n",
    "        return x_o, y_o\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.text_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = UL2Dataset(\n",
    "    [\"1n 2b 3g 4k 5i 6g 7i 8p 9o 11 22 55 44 77 88 99 33\"],\n",
    "    probabilities={\"s\": 0.2, \"b\": 0.3, \"c\": 0.5},\n",
    "    tokenizer=tokenizer)\n",
    "for x, y in d:\n",
    "    print(x)\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exists(val):\n",
    "    return val is not None\n",
    "\n",
    "def default(val, d):\n",
    "    return val if exists(val) else d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5LayerNorm(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        \"\"\"\n",
    "        Construct a layernorm module in the T5 style. No bias and no subtraction of mean.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(config[\"d_model\"]))\n",
    "        self.variance_epsilon = config[\"norm_eps\"]\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # T5 uses a layer_norm which only scales and doesn't shift, which is also known as Root Mean\n",
    "        # Square Layer Normalization https://arxiv.org/abs/1910.07467 thus varience is calculated\n",
    "        # w/o mean and there is no bias. Additionally we want to make sure that the accumulation for\n",
    "        # half-precision inputs is done in fp32\n",
    "\n",
    "        variance = x.to(torch.float32).pow(2).mean(-1, keepdim=True)\n",
    "        x = x * torch.rsqrt(variance + self.variance_epsilon)\n",
    "\n",
    "        # convert into half-precision if necessary\n",
    "        if self.weight.dtype in [torch.float16, torch.bfloat16]:\n",
    "            x = x.to(self.weight.dtype)\n",
    "\n",
    "        return self.weight * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.wi_0 = nn.Linear(config[\"d_model\"], config[\"d_ff\"], bias=False)\n",
    "        self.wi_1 = nn.Linear(config[\"d_model\"], config[\"d_ff\"], bias=False)\n",
    "        self.wo = nn.Linear(config[\"d_ff\"], config[\"d_model\"], bias=False)\n",
    "        self.dropout = nn.Dropout(config[\"dropout_rate\"])\n",
    "        self.act = nn.SiLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_gelu = self.act(self.wi_0(x))\n",
    "        x_linear = self.wi_1(x)\n",
    "        x = x_gelu * x_linear\n",
    "        x = self.dropout(x)\n",
    "        x = self.wo(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5RelativePositionBias(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.scale = config[\"dim_head\"] ** -0.5\n",
    "        self.causal = config[\"causal\"]\n",
    "        self.num_buckets = config[\"num_buckets\"]\n",
    "        self.max_distance = config[\"max_distance\"]\n",
    "        self.relative_attention_bias = nn.Embedding(config[\"num_buckets\"], config[\"heads\"])\n",
    "\n",
    "    @staticmethod\n",
    "    def _relative_position_bucket(relative_position, causal = True, num_buckets = 32, max_distance = 128):\n",
    "        ret = 0\n",
    "        n = -relative_position\n",
    "        if not causal:\n",
    "            num_buckets //= 2\n",
    "            ret += (n < 0).long() * num_buckets\n",
    "            n = torch.abs(n)\n",
    "        else:\n",
    "            n = torch.max(n, torch.zeros_like(n))\n",
    "\n",
    "        max_exact = num_buckets // 2\n",
    "        is_small = n < max_exact\n",
    "\n",
    "        val_if_large = max_exact + (\n",
    "            torch.log(n.float() / max_exact) / math.log(max_distance / max_exact) * (num_buckets - max_exact)\n",
    "        ).long()\n",
    "        val_if_large = torch.min(val_if_large, torch.full_like(val_if_large, num_buckets - 1))\n",
    "\n",
    "        ret += torch.where(is_small, n, val_if_large)\n",
    "        return ret\n",
    "\n",
    "    def forward(self, qk_dots):\n",
    "        i, j, device = *qk_dots.shape[-2:], qk_dots.device\n",
    "        q_pos = torch.arange(j - i, j, dtype = torch.long, device = device)\n",
    "        k_pos = torch.arange(j, dtype = torch.long, device = device)\n",
    "        rel_pos = k_pos[None, :] - q_pos[:, None]\n",
    "        rp_bucket = self._relative_position_bucket(\n",
    "            rel_pos, \n",
    "            causal = self.causal, \n",
    "            num_buckets = self.num_buckets, \n",
    "            max_distance = self.max_distance\n",
    "        )\n",
    "        values = self.relative_attention_bias(rp_bucket)\n",
    "        bias = rearrange(values, 'i j h -> h i j')\n",
    "        return qk_dots + (bias * self.scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5SelfAttention(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        inner_dim = config[\"dim_head\"] * config[\"heads\"]\n",
    "        self.heads = config[\"heads\"]\n",
    "        self.scale = config[\"dim_head\"] ** -0.5\n",
    "        self.causal = config[\"causal\"]\n",
    "\n",
    "        self.to_q = nn.Linear(config[\"d_model\"], inner_dim, bias = False)\n",
    "        self.to_k = nn.Linear(config[\"d_model\"], inner_dim, bias = False)\n",
    "        self.to_v = nn.Linear(config[\"d_model\"], inner_dim, bias = False)\n",
    "        self.to_out = nn.Linear(inner_dim, config[\"d_model\"])\n",
    "\n",
    "        self.relative_position_bias = T5RelativePositionBias(config)\n",
    "\n",
    "        self.dropout = nn.Dropout(config[\"dropout_rate\"])\n",
    "\n",
    "    def forward(self, x, mask = None):\n",
    "        b, n, _, h = *x.shape, self.heads\n",
    "        q, k, v = self.to_q(x), self.to_k(x), self.to_v(x)\n",
    "\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = h), (q, k, v))\n",
    "\n",
    "        q = q * self.scale\n",
    "\n",
    "        sim = torch.einsum('b h i d, b h j d -> b h i j', q, k)\n",
    "\n",
    "        sim = self.relative_position_bias(sim)\n",
    "        # mask\n",
    "\n",
    "        mask_value = -torch.finfo(sim.dtype).max\n",
    "\n",
    "        if mask is not None:\n",
    "            sim = sim.masked_fill_(~mask, mask_value)\n",
    "\n",
    "        if self.causal:\n",
    "            i, j = sim.shape[-2:]\n",
    "            causal_mask = torch.ones((i, j), dtype = torch.bool, device = x.device).triu(j - i + 1)\n",
    "            sim = sim.masked_fill(causal_mask, mask_value)\n",
    "\n",
    "        # attention\n",
    "\n",
    "        attn = sim.softmax(dim = -1)\n",
    "        attn = self.dropout(attn)\n",
    "\n",
    "        # aggregate\n",
    "\n",
    "        out = torch.einsum('b h i j, b h j d -> b h i d', attn, v)\n",
    "        \n",
    "        # merge heads\n",
    "\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "        \n",
    "        # combine heads and linear output\n",
    "\n",
    "        return self.to_out(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5CrossAttention(nn.Module):\n",
    "    def __init__(self,config):\n",
    "        super().__init__()\n",
    "        inner_dim = config[\"dim_head\"] * config[\"heads\"]\n",
    "        context_dim = default(config[\"context_dim\"], config[\"d_model\"])\n",
    "\n",
    "        self.heads = config[\"heads\"]\n",
    "        self.scale = config[\"dim_head\"] ** -0.5\n",
    "\n",
    "        self.to_q = nn.Linear(config[\"d_model\"], inner_dim, bias = False)\n",
    "        self.to_k = nn.Linear(config[\"context_dim\"], inner_dim, bias = False)\n",
    "        self.to_v = nn.Linear(config[\"context_dim\"], inner_dim, bias = False)\n",
    "        self.to_out = nn.Linear(inner_dim, config[\"d_model\"])\n",
    "\n",
    "        self.dropout = nn.Dropout(config[\"dropout_rate\"])\n",
    "\n",
    "    def forward(self, x, context, mask = None, context_mask = None):\n",
    "        b, n, _, h = *x.shape, self.heads\n",
    "\n",
    "        kv_input = default(context, x)\n",
    "\n",
    "        q, k, v = self.to_q(x), self.to_k(kv_input), self.to_v(kv_input)\n",
    "\n",
    "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = h), (q, k, v))\n",
    "\n",
    "        q = q * self.scale\n",
    "\n",
    "        sim = torch.einsum('b h i d, b h j d -> b h i j', q, k)\n",
    "\n",
    "        # mask\n",
    "\n",
    "        mask_value = -torch.finfo(sim.dtype).max\n",
    "\n",
    "        if mask is not None:\n",
    "            sim = sim.masked_fill_(~mask, mask_value)\n",
    "\n",
    "        if context_mask is not None:\n",
    "            sim = sim.masked_fill_(~context_mask[:, None, :], mask_value)\n",
    "\n",
    "        # attention\n",
    "\n",
    "        attn = sim.softmax(dim = -1)\n",
    "        attn = self.dropout(attn)\n",
    "\n",
    "        # aggregate\n",
    "\n",
    "        out = torch.einsum('b h i j, b h j d -> b h i d', attn, v)\n",
    "        \n",
    "        # merge heads\n",
    "\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')\n",
    "               \n",
    "        # combine heads and linear output\n",
    "\n",
    "        return self.to_out(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SublayerConnection(nn.Module):\n",
    "    \"\"\"\n",
    "    A residual connection followed by a layer norm.\n",
    "    Note for code simplicity the norm is first as opposed to last.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super(SublayerConnection, self).__init__()\n",
    "        self.norm = T5LayerNorm(config)\n",
    "        self.dropout = nn.Dropout(config[\"dropout_rate\"])\n",
    "\n",
    "    def forward(self, sublayer, x, **kwargs):\n",
    "        \"Apply residual connection to any sublayer with the same size.\"\n",
    "        return x + self.dropout(sublayer(self.norm(x), **kwargs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5EncoderLayer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.att = T5SelfAttention(config)\n",
    "        self.mlp = FeedForward(config)\n",
    "        \n",
    "        self.sublayer1 = SublayerConnection(config)\n",
    "        self.sublayer2 = SublayerConnection(config)\n",
    "\n",
    "    def forward(self, x, mask = None):\n",
    "        x = self.sublayer1(self.att, x, mask = mask)\n",
    "        \n",
    "        x = self.sublayer1(self.mlp, x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5Encoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        # self.token_emb = nn.Embedding(config[\"num_tokens\"], config[\"d_model\"])\n",
    "\n",
    "        self.layers = nn.ModuleList([T5EncoderLayer(config) for _ in range(config[\"depth\"])])\n",
    "\n",
    "        self.final_norm = T5LayerNorm(config)\n",
    "\n",
    "    def forward(self, x, mask = None):\n",
    "        # x = self.token_emb(x)\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "\n",
    "        x = self.final_norm(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5DecoderLayer(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.att = T5SelfAttention(config)\n",
    "        self.cross_attn = T5CrossAttention(config)\n",
    "        self.mlp = FeedForward(config)\n",
    "        \n",
    "        self.sublayer1 = SublayerConnection(config)\n",
    "        self.sublayer2 = SublayerConnection(config)\n",
    "        self.sublayer3 = SublayerConnection(config)\n",
    "\n",
    "    def forward(self, x, context, mask = None, context_mask = None):\n",
    "        x = self.sublayer1(self.att, x, mask = mask)\n",
    "        \n",
    "        x = self.sublayer2(self.cross_attn, x, context = context, mask = mask, context_mask = context_mask)\n",
    "        \n",
    "        x = self.sublayer3(self.mlp, x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5Decoder(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(config[\"num_tokens\"], config[\"d_model\"])\n",
    "        \n",
    "        self.layers = nn.ModuleList([T5DecoderLayer(config) for _ in range(config[\"depth\"])])\n",
    "        \n",
    "        self.final_norm = T5LayerNorm(config)\n",
    "\n",
    "    def forward(self, x, context, mask = None, context_mask = None):\n",
    "        x = self.token_emb(x)\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x = layer(x, context, mask, context_mask)\n",
    "\n",
    "        x = self.final_norm(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5(nn.Module):\n",
    "    def __init__(self, encoder_config, decoder_config, tie_token_emb=True):\n",
    "        super().__init__()\n",
    "        self.token_emb = nn.Embedding(encoder_config[\"num_tokens\"], encoder_config[\"d_model\"])\n",
    "        self.encoder = T5Encoder(encoder_config)\n",
    "        \n",
    "        self.decoder = T5Decoder(decoder_config)\n",
    "\n",
    "        self.to_logits = nn.Linear(decoder_config[\"d_model\"], decoder_config[\"num_tokens\"], bias=False)\n",
    "\n",
    "        # tie weights\n",
    "        if tie_token_emb:\n",
    "            self.token_emb.weight = self.decoder.token_emb.weight\n",
    "\n",
    "    def forward(self, src, tgt, mask = None, context_mask = None):\n",
    "        x = self.token_emb(src)\n",
    "        x = self.encoder(x, mask = mask)\n",
    "        x = self.decoder(tgt, x, mask = mask, context_mask = context_mask)\n",
    "        x = self.to_logits(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr_scheduler(optimizer, batch_size = 64, last_epoch=-1):\n",
    "    lr_start   = 0.00001\n",
    "    lr_max     = 0.00003 * batch_size\n",
    "    lr_min     = 0.000001\n",
    "    lr_ramp_ep = 30\n",
    "    lr_sus_ep  = 0\n",
    "    lr_decay   = 0.9\n",
    "    def lrfn(epoch):\n",
    "        if epoch < lr_ramp_ep: lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n",
    "        elif epoch < lr_ramp_ep + lr_sus_ep: lr = lr_max\n",
    "        else: lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n",
    "        return lr\n",
    "    lr_scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lrfn, last_epoch=last_epoch, verbose=False)\n",
    "    return lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loader(ds, ul2_arg, batch_size=64):\n",
    "    ul2_data = UL2Dataset(ds, tokenizer=tokenizer, mu=ul2_arg[\"mu\"], d=ul2_arg[\"d\"], probabilities=ul2_arg[\"probabilities\"])\n",
    "    inputs = []\n",
    "    targets = []\n",
    "    for j in range(len(ul2_data)):\n",
    "        x, y = ul2_data[j]\n",
    "        inputs.append(x)\n",
    "        targets.append(y)\n",
    "    t = tokenizer([*inputs, *targets], padding=True, truncation=True)\n",
    "    \n",
    "    ds_set = TensorDataset(\n",
    "        torch.tensor(t['input_ids'][:len(t['input_ids'])//2], dtype=torch.long),\n",
    "        torch.tensor(t['attention_mask'][:len(t['input_ids'])//2], dtype=torch.long),\n",
    "        torch.tensor(t['input_ids'][len(t['input_ids'])//2:], dtype=torch.long))\n",
    "    \n",
    "    return DataLoader(ds_set, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, val_loader):\n",
    "    if not isinstance(model, nn.DataParallel):\n",
    "        model = nn.DataParallel(model)\n",
    "    \n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    loss_list = []\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (x, att, labels) in enumerate(val_loader):\n",
    "\n",
    "            x = x.to(device, dtype=torch.long)\n",
    "            att = att.to(device, dtype=torch.long)\n",
    "            labels = labels.to(device, dtype=torch.long)\n",
    "            \n",
    "            y = model(x, att)\n",
    "            loss = loss_fn(y.reshape((-1, y.shape[-1])), labels.reshape(-1))\n",
    "\n",
    "            loss_list.append(loss.to('cpu').detach())\n",
    "\n",
    "\n",
    "    loss = np.mean(loss_list)\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, args, checkpoint=None):\n",
    "    torch.set_grad_enabled(True)\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    if not isinstance(model, nn.DataParallel):\n",
    "        model = nn.DataParallel(model)\n",
    "\n",
    "    model = model.to(device)\n",
    "    \n",
    "    # Set up the optimizer\n",
    "    trainables = [p for p in model.parameters() if p.requires_grad]\n",
    "    print('Total parameter number is : {:.3f} million'.format(sum(p.numel() for p in model.parameters()) / 1e6))\n",
    "    print('Total trainable parameter number is : {:.3f} million'.format(sum(p.numel() for p in trainables) / 1e6))\n",
    "\n",
    "    if args[\"optimizer\"] == 'adam':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=args[\"lr\"], weight_decay=5e-7, betas=(0.95, 0.999))\n",
    "    elif args[\"optimizer\"] == \"adamw\":\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=args[\"lr\"], weight_decay=5e-7, amsgrad=True)\n",
    "    else:\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr=args[\"lr\"], momentum=0.9, nesterov=True, weight_decay=5e-7)\n",
    "    \n",
    "    last_epoch = -1\n",
    "    if checkpoint:\n",
    "        model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "        optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "        last_epoch = checkpoint[\"chunk\"]\n",
    "    \n",
    "    if args[\"scheduler\"] == \"LambdaLR\":\n",
    "        scheduler = get_lr_scheduler(optimizer, batch_size = args[\"batch_size\"] * args[\"NUM_ACCUMULATION_STEPS\"], last_epoch=last_epoch)\n",
    "    elif args[\"scheduler\"] == \"cosine\":\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=args[\"cosin_T_max\"], last_epoch=last_epoch)\n",
    "    else:\n",
    "        scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, list(range(args[\"lrscheduler_start\"], 1000, args[\"lrscheduler_step\"])), gamma=args[\"lrscheduler_decay\"], last_epoch=last_epoch)\n",
    "    \n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    \n",
    "    chunksize = 10 ** 5\n",
    "    with pd.read_csv(\"/kaggle/input/nlp-dataset/books.csv\", chunksize=chunksize) as reader:\n",
    "        for i, chunk in enumerate(reader):\n",
    "            if last_epoch >= i:\n",
    "                continue\n",
    "            chunk = chunk[[\"text\"]]\n",
    "            train_chunk, test_chunk = train_test_split(chunk, test_size=0.1, random_state=42)\n",
    "            batch_size = args['batch_size']\n",
    "            ul2_arg = {\n",
    "                \"mu\": 3,\n",
    "                \"d\": 0.2,\n",
    "                \"probabilities\": {\"s\": 0.2, \"b\": 0.3, \"c\": 0.5}\n",
    "            }\n",
    "            train_loader =  get_data_loader(\n",
    "                train_chunk[\"text\"].tolist(),\n",
    "                ul2_arg=ul2_arg,\n",
    "                batch_size=batch_size)\n",
    "            test_loader = get_data_loader(\n",
    "                test_chunk[\"text\"].tolist(),\n",
    "                ul2_arg=ul2_arg,\n",
    "                batch_size=batch_size)\n",
    "            \n",
    "            \n",
    "            begin_time = time.time()\n",
    "            model.train()\n",
    "            \n",
    "            loss_train = []\n",
    "\n",
    "            for k, (x, att, labels) in enumerate(train_loader):\n",
    "                x = x.to(device, dtype=torch.long)\n",
    "                att = att.to(device, dtype=torch.long)\n",
    "                labels = labels.to(device, dtype=torch.long)\n",
    "\n",
    "                y = model(x, att)\n",
    "\n",
    "                loss = loss_fn(y.reshape((-1, y.shape[-1])), labels.reshape(-1))\n",
    "                \n",
    "                loss = loss / args[\"NUM_ACCUMULATION_STEPS\"]\n",
    "\n",
    "                loss.backward()\n",
    "                \n",
    "                if ((k + 1) % args[\"NUM_ACCUMULATION_STEPS\"] == 0) or (k + 1 == len(train_loader)):\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                loss_train.append(loss.clone().detach().to('cpu'))\n",
    "\n",
    "\n",
    "            train_loss = np.mean(loss_train)\n",
    "            val_loss = validate(model, test_loader)\n",
    "            lr = scheduler.get_last_lr()[0]\n",
    "            \n",
    "            del train_loader, test_loader, train_chunk, test_chunk\n",
    "            gc.collect()\n",
    "\n",
    "            print(f\"chunk: {i}, lr: {lr:.8f}, train loss: {train_loss:.6f}, val loss: {val_loss:.6f}\")\n",
    "\n",
    "            scheduler.step()\n",
    "            \n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'chunk': i\n",
    "            }, 'model.pth')\n",
    "            \n",
    "            if time.time() - start_time > 60*60*9:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    \"lr\": 0.001,\n",
    "    \"lrscheduler_start\": 15,\n",
    "    \"lrscheduler_step\": 10,\n",
    "    \"lrscheduler_decay\": 0.5,\n",
    "    \"warmup\": True,\n",
    "    \"optimizer\": [\"adam\", \"adamw\", \"sgd\"][1],\n",
    "    \"scheduler\": [\"LambdaLR\", \"cosine\"][0],\n",
    "    \"batch_size\": 8,\n",
    "    \"NUM_ACCUMULATION_STEPS\": 1024//8\n",
    "}\n",
    "\n",
    "d_model =  512\n",
    "depth = 8\n",
    "encoder_config = {\n",
    "    \"d_model\": d_model,\n",
    "    \"d_ff\": int(d_model*2.5),\n",
    "    \"dropout_rate\": 0,\n",
    "    \"causal\": False,\n",
    "    \"num_buckets\": 32,\n",
    "    \"max_distance\": 128,\n",
    "    \"heads\": 12,\n",
    "    \"dim_head\": 64,\n",
    "    \"depth\": depth,\n",
    "    \"num_tokens\": tokenizer.vocab_size,\n",
    "    \"norm_eps\": 1e-6\n",
    "}\n",
    "decoder_config = {\n",
    "    \"d_model\": d_model,\n",
    "    \"d_ff\": int(d_model*2.5),\n",
    "    \"dropout_rate\": 0,\n",
    "    \"causal\": False,\n",
    "    \"num_buckets\": 32,\n",
    "    \"max_distance\": 128,\n",
    "    \"heads\": 12,\n",
    "    \"dim_head\": 64,\n",
    "    \"context_dim\": encoder_config[\"d_model\"],\n",
    "    \"depth\": depth,\n",
    "    \"num_tokens\": tokenizer.vocab_size,\n",
    "    \"norm_eps\": 1e-6\n",
    "}\n",
    "\n",
    "model = T5(encoder_config, decoder_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, args, checkpoint = torch.load(\"/kaggle/input/t5model/model.pth\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
